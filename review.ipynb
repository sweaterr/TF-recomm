{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "os.chdir(\"/Users/sweaterr/PycharmProjects/TF-recomm\")\n",
    "import dataio\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from six import next\n",
    "\n",
    "np.random.seed(13575)\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "USER_NUM = 6040\n",
    "ITEM_NUM = 3952\n",
    "DIM = 15\n",
    "EPOCH_MAX = 100\n",
    "DEVICE = \"/cpu:0\"\n",
    "\n",
    "import time\n",
    "def get_data():\n",
    "    df = dataio.read_process(\"/tmp/movielens/ml-1m/ratings.dat\", sep=\"::\")\n",
    "    rows = len(df)\n",
    "    df = df.iloc[np.random.permutation(rows)].reset_index(drop=True)\n",
    "    split_index = int(rows * 0.9)\n",
    "    df_train = df[0:split_index]\n",
    "    df_test = df[split_index:].reset_index(drop=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.first of         user  item  rate          st\n0       1893  1692   4.0   974695176\n1       5947  2312   4.0   957190990\n2        162   365   2.0   977323187\n3       5117   456   3.0   962294766\n4       2029   315   1.0   974929369\n5       2220  1844   5.0   974603135\n6       4385  3385   3.0   965172804\n7       5779   282   4.0   958156569\n8       3617  3740   2.0   966600773\n9       3640   584   4.0   966482594\n10       515   110   4.0   976205508\n11      5138   160   3.0   962060976\n12      3032  1290   5.0   970291018\n13       521  1199   3.0   976196943\n14      3409  1273   5.0   967416389\n15      3733  2430   5.0   966194170\n16        76  2540   2.0   977813753\n17      1299  1320   5.0   974786901\n18      5874  3750   4.0   965274403\n19      5538   925   5.0   986573601\n20      3361   140   4.0   967672860\n21      3649   378   4.0   966460630\n22      1828  1196   3.0   974696861\n23      4276  2659   5.0   983696191\n24      5538  2301   4.0  1027814481\n25      5554   552   5.0   959648977\n26      1604    18   2.0   975383005\n27      1183  2247   4.0   974852578\n28      4039  2018   5.0   965504149\n29      4883  1966   3.0   962746447\n...      ...   ...   ...         ...\n900158  5949  1306   3.0   957181473\n900159  4992  1087   4.0   962594434\n900160  2206  3896   4.0   974603104\n900161  1198   349   4.0   974847916\n900162  6015  2794   3.0   956780757\n900163  3719   363   3.0   966253320\n900164  4017   291   4.0   965528519\n900165  4465  2021   4.0   965070532\n900166  3282  3697   3.0   968122571\n900167  4815   523   5.0   966526595\n900168  5885  1579   4.0   957485695\n900169  2210  1632   4.0   974605506\n900170  2452  1212   5.0   974189331\n900171  5861  1135   5.0   957672690\n900172  5624  2790   4.0   959088950\n900173  5654  1783   4.0   958843916\n900174   148  3727   4.0   993154501\n900175  4489  3601   3.0   965009362\n900176   139  1220   5.0   993950520\n900177  5581  3340   5.0   959282034\n900178  4446  1335   2.0   965256135\n900179  5949  3506   4.0   957182426\n900180  4646  2962   4.0   984287092\n900181  3807  1946   2.0   965970632\n900182  1330  3385   4.0   974953684\n900183  4971  2570   4.0   962607373\n900184  2115  3004   4.0   974760264\n900185  3756  1967   5.0   966096999\n900186  5794  3081   1.0   958144283\n900187  5861   479   4.0   957670444\n\n[900188 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_train.first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train\n",
    "test = df_test\n",
    "samples_per_batch = len(train) // BATCH_SIZE\n",
    "\n",
    "iter_train = dataio.ShuffleIterator([train[\"user\"],\n",
    "                                     train[\"item\"],\n",
    "                                     train[\"rate\"]],\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "iter_test = dataio.OneEpochIterator([test[\"user\"],\n",
    "                                     test[\"item\"],\n",
    "                                     test[\"rate\"]],\n",
    "                                    batch_size=-1)\n",
    "\n",
    "user_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_user\")\n",
    "item_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_item\")\n",
    "rate_batch = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_svd(user_batch, item_batch, user_num, item_num, dim=5, device=\"/cpu:0\"):\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        bias_global = tf.get_variable(\"bias_global\", shape=[])\n",
    "        w_bias_user = tf.get_variable(\"embd_bias_user\", shape=[user_num])\n",
    "        w_bias_item = tf.get_variable(\"embd_bias_item\", shape=[item_num])\n",
    "        bias_user = tf.nn.embedding_lookup(w_bias_user, user_batch, name=\"bias_user\")\n",
    "        bias_item = tf.nn.embedding_lookup(w_bias_item, item_batch, name=\"bias_item\")\n",
    "        w_user = tf.get_variable(\"embd_user\", shape=[user_num, dim],\n",
    "                                 initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        w_item = tf.get_variable(\"embd_item\", shape=[item_num, dim],\n",
    "                                 initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        embd_user = tf.nn.embedding_lookup(w_user, user_batch, name=\"embedding_user\")\n",
    "        embd_item = tf.nn.embedding_lookup(w_item, item_batch, name=\"embedding_item\")\n",
    "    with tf.device(device):\n",
    "        infer = tf.reduce_sum(tf.mul(embd_user, embd_item), 1)\n",
    "        infer = tf.add(infer, bias_global)\n",
    "        infer = tf.add(infer, bias_user)\n",
    "        infer = tf.add(infer, bias_item, name=\"svd_inference\")\n",
    "        regularizer = tf.add(tf.nn.l2_loss(embd_user), tf.nn.l2_loss(embd_item), name=\"svd_regularizer\")\n",
    "    return infer, regularizer\n",
    "\n",
    "\n",
    "def optimiaztion(infer, regularizer, rate_batch, learning_rate=0.001, reg=0.1, device=\"/cpu:0\"):\n",
    "    with tf.device(device):\n",
    "        cost_l2 = tf.nn.l2_loss(tf.sub(infer, rate_batch))\n",
    "        panelty = tf.constant(reg, dtype=tf.float32, shape=[], name=\"l2\")\n",
    "        cost = tf.add(cost_l2, tf.mul(regularizer, panelty))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    return cost, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer, regularizer = inference_svd(user_batch, item_batch, user_num=USER_NUM, item_num=ITEM_NUM, dim=DIM,device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_op = optimiaztion(infer, regularizer, rate_batch, learning_rate=0.001, reg=0.05, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    return np.clip(x, 1.0, 5.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(\"{} {} {} {}\".format(\"epoch\", \"train_error\", \"val_error\", \"elapsed_time\"))\n",
    "    errors = deque(maxlen=samples_per_batch)\n",
    "    start = time.time()\n",
    "    for i in range(EPOCH_MAX * samples_per_batch):\n",
    "        users, items, rates = next(iter_train)\n",
    "        _, pred_batch = sess.run([train_op, infer], feed_dict={user_batch: users,\n",
    "                                                               item_batch: items,\n",
    "                                                               rate_batch: rates})\n",
    "        pred_batch = clip(pred_batch)\n",
    "        errors.append(np.power(pred_batch - rates, 2))\n",
    "        if i % samples_per_batch == 0:\n",
    "            train_err = np.sqrt(np.mean(errors))\n",
    "            test_err2 = np.array([])\n",
    "            for users, items, rates in iter_test:\n",
    "                pred_batch = sess.run(infer, feed_dict={user_batch: users,\n",
    "                                                        item_batch: items})\n",
    "                pred_batch = clip(pred_batch)\n",
    "                test_err2 = np.append(test_err2, np.power(pred_batch - rates, 2))\n",
    "            end = time.time()\n",
    "            print(\"{:3d} {:f} {:f} {:f}(s)\".format(i // samples_per_batch, train_err, np.sqrt(np.mean(test_err2)),\n",
    "                                                   end - start))\n",
    "            start = end\n",
    "\n",
    "    output_graph_def = graph_util.extract_sub_graph(sess.graph.as_graph_def(),\n",
    "                                                                     [\"svd_inference\", \"svd_regularizer\"])\n",
    "    tf.train.SummaryWriter(logdir=\"/tmp/svd\", graph_def=output_graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}